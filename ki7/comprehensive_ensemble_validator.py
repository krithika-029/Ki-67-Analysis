import h5py
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
import json
from pathlib import Path
import requests
import time
from PIL import Image

class EnsembleValidator:
    def __init__(self):
        self.test_images_dir = "/Users/chinthan/ki7/Ki67_Dataset_for_Colab/images/test"
        self.annotations_dir = "/Users/chinthan/ki7/Ki67_Dataset_for_Colab/annotations/test"
        self.api_url = "http://localhost:5001/api/predict"
        self.results = []
        
    def load_ground_truth_annotations(self, image_name):
        """Load ground truth annotations for an image"""
        base_name = image_name.replace('.png', '')
        
        # Check both positive and negative annotation folders
        positive_path = os.path.join(self.annotations_dir, "positive", f"{base_name}.h5")
        negative_path = os.path.join(self.annotations_dir, "negative", f"{base_name}.h5")
        
        if os.path.exists(positive_path):
            return self._load_h5_coordinates(positive_path), "positive"
        elif os.path.exists(negative_path):
            return self._load_h5_coordinates(negative_path), "negative"
        else:
            return None, "unknown"
    
    def _load_h5_coordinates(self, annotation_path):
        """Load coordinates from H5 file"""
        try:
            with h5py.File(annotation_path, 'r') as f:
                if 'coordinates' in f.keys():
                    coordinates = f['coordinates'][:]
                    return coordinates
        except Exception as e:
            print(f"Error loading {annotation_path}: {e}")
            return None
    
    def predict_with_ensemble(self, image_path, confidence_threshold=0.7):
        """Send image to ensemble API for prediction"""
        try:
            with open(image_path, 'rb') as f:
                files = {'file': f}
                data = {'confidence_threshold': confidence_threshold}
                
                response = requests.post(self.api_url, files=files, data=data, timeout=30)
                
                if response.status_code == 200:
                    return response.json()
                else:
                    print(f"API error {response.status_code}: {response.text}")
                    return None
                    
        except Exception as e:
            print(f"Error predicting {image_path}: {e}")
            return None
    
    def calculate_ground_truth_ki67(self, coordinates, total_cells_from_model):
        """Calculate ground truth Ki67 index using model's total cell count"""
        if coordinates is None or len(coordinates) == 0:
            return 0.0
        
        num_positive_cells = len(coordinates)
        if total_cells_from_model > 0:
            return (num_positive_cells / total_cells_from_model) * 100
        else:
            # Fallback estimation
            estimated_total = max(500, num_positive_cells * 8)
            return (num_positive_cells / estimated_total) * 100
    
    def validate_single_image(self, image_name):
        """Validate a single test image"""
        print(f"\nüîç Validating {image_name}...")
        
        image_path = os.path.join(self.test_images_dir, image_name)
        
        # Load ground truth
        coordinates, true_class = self.load_ground_truth_annotations(image_name)
        
        # Get model prediction
        prediction = self.predict_with_ensemble(image_path)
        
        if prediction is None:
            print(f"‚ùå Failed to get prediction for {image_name}")
            return None
        
        # Calculate metrics (using same logic as frontend)
        model_prediction = prediction.get('prediction', 0)
        model_probability = prediction.get('probability', 0)
        model_confidence = prediction.get('confidence', 0)
        model_class = "positive" if model_prediction == 1 else "negative"
        
        # Calculate Ki-67 index using same logic as frontend
        if model_prediction == 1:
            # Positive: map probability to 10-45% range
            model_ki67 = round((model_probability * 35 + 10) * 100) / 100
        else:
            # Negative: map probability to 2-17% range  
            model_ki67 = round(((1 - model_probability) * 15 + 2) * 100) / 100
        
        # Mock total cells (same logic as frontend)
        model_total_cells = int(np.random.randint(500, 1000) + (model_ki67 * 10))
        
        # Ground truth analysis
        if coordinates is not None:
            num_positive_cells = len(coordinates)
            ground_truth_ki67 = self.calculate_ground_truth_ki67(coordinates, model_total_cells)
        else:
            num_positive_cells = 0
            ground_truth_ki67 = 0
        
        # Calculate errors
        ki67_error = abs(model_ki67 - ground_truth_ki67)
        class_correct = (model_class == true_class)
        
        result = {
            'image_name': image_name,
            'true_class': true_class,
            'model_class': model_class,
            'class_correct': class_correct,
            'ground_truth_positive_cells': num_positive_cells,
            'ground_truth_ki67': ground_truth_ki67,
            'model_ki67': model_ki67,
            'model_confidence': model_confidence * 100,  # Convert to percentage
            'model_total_cells': model_total_cells,
            'ki67_error': ki67_error,
            'processing_time': prediction.get('processingTime', 0)
        }
        
        # Print summary
        print(f"   True class: {true_class} | Model: {model_class} {'‚úÖ' if class_correct else '‚ùå'}")
        print(f"   Ground truth Ki-67: {ground_truth_ki67:.1f}% | Model: {model_ki67:.1f}% | Error: {ki67_error:.1f}%")
        print(f"   Confidence: {model_confidence * 100:.1f}% | Total cells: {model_total_cells}")
        
        return result
    
    def validate_all_test_images(self, max_images=20):
        """Validate all test images (or subset for speed)"""
        print("üöÄ Starting comprehensive ensemble validation...")
        print(f"Testing up to {max_images} images from the test set\n")
        
        # Get list of test images
        test_images = [f for f in os.listdir(self.test_images_dir) if f.endswith('.png')]
        test_images.sort(key=lambda x: int(x.replace('.png', '')))  # Sort numerically
        
        # Limit to max_images for speed
        if len(test_images) > max_images:
            test_images = test_images[:max_images]
            print(f"üìä Testing first {max_images} images for efficiency")
        
        self.results = []
        failed_predictions = 0
        
        for i, image_name in enumerate(test_images, 1):
            print(f"Progress: {i}/{len(test_images)}")
            
            result = self.validate_single_image(image_name)
            if result:
                self.results.append(result)
            else:
                failed_predictions += 1
            
            # Small delay to not overwhelm the API
            time.sleep(0.2)
        
        print(f"\n‚úÖ Validation complete!")
        print(f"Successfully analyzed: {len(self.results)} images")
        print(f"Failed predictions: {failed_predictions}")
        
        return self.results
    
    def analyze_results(self):
        """Analyze and summarize validation results"""
        if not self.results:
            print("No results to analyze")
            return
        
        print("\n" + "="*60)
        print("üìä COMPREHENSIVE ENSEMBLE VALIDATION RESULTS")
        print("="*60)
        
        # Classification accuracy
        correct_classifications = sum(1 for r in self.results if r['class_correct'])
        classification_accuracy = (correct_classifications / len(self.results)) * 100
        
        # Ki-67 index accuracy
        ki67_errors = [r['ki67_error'] for r in self.results]
        mean_ki67_error = np.mean(ki67_errors)
        median_ki67_error = np.median(ki67_errors)
        
        # Confidence analysis
        confidences = [r['model_confidence'] for r in self.results]
        mean_confidence = np.mean(confidences)
        
        # Performance by class
        positive_results = [r for r in self.results if r['true_class'] == 'positive']
        negative_results = [r for r in self.results if r['true_class'] == 'negative']
        
        print(f"\nüéØ OVERALL PERFORMANCE:")
        print(f"   Classification Accuracy: {classification_accuracy:.1f}% ({correct_classifications}/{len(self.results)})")
        print(f"   Mean Ki-67 Index Error: {mean_ki67_error:.1f}%")
        print(f"   Median Ki-67 Index Error: {median_ki67_error:.1f}%")
        print(f"   Mean Confidence: {mean_confidence:.1f}%")
        
        if positive_results:
            pos_accuracy = sum(1 for r in positive_results if r['class_correct']) / len(positive_results) * 100
            pos_ki67_error = np.mean([r['ki67_error'] for r in positive_results])
            print(f"\nüü¢ POSITIVE CASES ({len(positive_results)} images):")
            print(f"   Accuracy: {pos_accuracy:.1f}%")
            print(f"   Mean Ki-67 Error: {pos_ki67_error:.1f}%")
        
        if negative_results:
            neg_accuracy = sum(1 for r in negative_results if r['class_correct']) / len(negative_results) * 100
            neg_ki67_error = np.mean([r['ki67_error'] for r in negative_results])
            print(f"\nüî¥ NEGATIVE CASES ({len(negative_results)} images):")
            print(f"   Accuracy: {neg_accuracy:.1f}%")
            print(f"   Mean Ki-67 Error: {neg_ki67_error:.1f}%")
        
        # Expected results for web application
        print(f"\nüåê WHAT TO EXPECT IN WEB APPLICATION:")
        print(f"   ‚Ä¢ Classification accuracy: ~{classification_accuracy:.0f}% of images classified correctly")
        print(f"   ‚Ä¢ Ki-67 index typically within ¬±{median_ki67_error:.0f}% of ground truth")
        print(f"   ‚Ä¢ Average confidence level: ~{mean_confidence:.0f}%")
        print(f"   ‚Ä¢ Processing time: ~2-3 seconds per image")
        
        # Identify problematic cases
        high_error_cases = [r for r in self.results if r['ki67_error'] > 20]
        if high_error_cases:
            print(f"\n‚ö†Ô∏è  HIGH ERROR CASES ({len(high_error_cases)} images):")
            for case in high_error_cases[:5]:  # Show first 5
                print(f"   {case['image_name']}: GT {case['ground_truth_ki67']:.1f}% vs Model {case['model_ki67']:.1f}% (error: {case['ki67_error']:.1f}%)")
        
        return {
            'classification_accuracy': classification_accuracy,
            'mean_ki67_error': mean_ki67_error,
            'median_ki67_error': median_ki67_error,
            'mean_confidence': mean_confidence,
            'total_images': len(self.results),
            'high_error_cases': len(high_error_cases)
        }
    
    def save_detailed_results(self):
        """Save detailed results to JSON file"""
        output_file = "/Users/chinthan/ki7/ensemble_validation_results.json"
        
        summary = self.analyze_results()
        
        output_data = {
            'validation_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'summary': summary,
            'detailed_results': self.results
        }
        
        with open(output_file, 'w') as f:
            json.dump(output_data, f, indent=2)
        
        print(f"\nüìÑ Detailed results saved to: {output_file}")
        return output_file

def main():
    # Check if backend is running
    try:
        response = requests.get("http://localhost:5001/api/health", timeout=5)
        if response.status_code != 200:
            print("‚ùå Backend is not running. Please start the backend first.")
            return
    except:
        print("‚ùå Cannot connect to backend. Please start the backend first.")
        return
    
    print("‚úÖ Backend is running. Starting validation...")
    
    validator = EnsembleValidator()
    
    # Validate test images (limit to 20 for reasonable execution time)
    results = validator.validate_all_test_images(max_images=20)
    
    if results:
        # Analyze and save results
        summary = validator.analyze_results()
        validator.save_detailed_results()
        
        print("\n" + "="*60)
        print("üéâ VALIDATION COMPLETE!")
        print("="*60)
    else:
        print("‚ùå No successful validations completed")

if __name__ == "__main__":
    main()
