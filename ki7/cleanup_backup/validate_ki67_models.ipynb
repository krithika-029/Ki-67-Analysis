{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d163513",
   "metadata": {},
   "source": [
    "# Ki-67 Model Validation in VS Code\n",
    "\n",
    "This notebook validates the 3 trained Ki-67 models (InceptionV3, ResNet50, ViT) using the Ki67_Dataset_for_Colab dataset directly in VS Code.\n",
    "\n",
    "## üìã What we'll validate:\n",
    "1. ‚úÖ Load trained model weights (.pth files)\n",
    "2. ‚úÖ Test on Ki67_Dataset_for_Colab dataset  \n",
    "3. ‚úÖ Calculate comprehensive metrics\n",
    "4. ‚úÖ Create ensemble predictions\n",
    "5. ‚úÖ Generate confusion matrices\n",
    "6. ‚úÖ Compare results with training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "try:\n",
    "    import timm\n",
    "    print(\"‚úÖ timm available for ViT model\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  timm not available, will use fallback CNN for ViT\")\n",
    "    timm = None\n",
    "\n",
    "print(\"üî¨ Ki-67 Model Validation System\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc39c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths (adjust these paths to match your local setup)\n",
    "DATASET_ZIP_PATH = \"/Users/chinthan/ki7/Ki67_Dataset_for_Colab.zip\"  # Adjust this path\n",
    "MODELS_PATH = \"/Users/chinthan/ki7\"  # Path where your .pth files are located\n",
    "EXTRACT_PATH = \"/Users/chinthan/ki7/ki67_validation_dataset\"\n",
    "\n",
    "def extract_dataset(dataset_zip_path, extract_path):\n",
    "    \"\"\"Extract the Ki67 dataset\"\"\"\n",
    "    if os.path.exists(dataset_zip_path):\n",
    "        print(f\"‚úÖ Found dataset at: {dataset_zip_path}\")\n",
    "        \n",
    "        os.makedirs(extract_path, exist_ok=True)\n",
    "        \n",
    "        print(\"Extracting dataset...\")\n",
    "        with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        \n",
    "        print(\"‚úÖ Dataset extracted successfully!\")\n",
    "        \n",
    "        # List extracted contents\n",
    "        for root, dirs, files in os.walk(extract_path):\n",
    "            level = root.replace(extract_path, '').count(os.sep)\n",
    "            indent = ' ' * 2 * level\n",
    "            print(f'{indent}{os.path.basename(root)}/')\n",
    "            subindent = ' ' * 2 * (level + 1)\n",
    "            for file in files[:5]:  # Show first 5 files\n",
    "                print(f'{subindent}{file}')\n",
    "            if len(files) > 5:\n",
    "                print(f'{subindent}... and {len(files)-5} more files')\n",
    "        \n",
    "        return extract_path\n",
    "    else:\n",
    "        print(f\"‚ùå Dataset not found at: {dataset_zip_path}\")\n",
    "        print(\"Please update DATASET_ZIP_PATH to the correct location\")\n",
    "        return None\n",
    "\n",
    "# Extract dataset\n",
    "dataset_path = extract_dataset(DATASET_ZIP_PATH, EXTRACT_PATH)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
